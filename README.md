
# Schedule

| Week      | HW Code                                            | Lecture Topic                               | Lecture Concepts                                                    |
|-----------|----------------------------------------------------|-------------------------------------|-----------------------------------------------------------------|
| **1**     | MCP, Local LLM with Ollama & LangChain | Intro to LLMs & Prompt Engineering  | Generative AI, prompting techniques (CO-STAR), JSON/XML output  |
| **2**     | OCR on PDFs (Data Extraction and Corpus Construction) | LLM Architecture & Training         | Transformers, hallucination, SFT/DPO/PPO, scaling laws          |
| **3**     | Voice Agent Development | Data Collection & Extraction        | Web scraping, OCR (Tesseract/Surya), ASR (Whisper), data cleaning |
| **4**     | RAG with arXiv Papers | Retrieval-Augmented Generation (RAG)| Embeddings, chunking, vector DBs, LangChain                     |
| **5**     | Embedding Database Optimization with hybrid retrieval| Supervised Fine-Tuning (SFT) I      | Full vs. LoRA fine-tuning, ChatML format, TRL/Deepspeed         |
| **6**     | Extending Voice Agent with Function Calling | Supervised Fine-Tuning (SFT) II     | Synthetic data, quality checks, LLM-as-judge                    |
| **7**     |  Fine-tuning with Synthetic Data (QLoRA)   | Model Alignment                     | RLHF, DPO/PPO, reward modeling, data labeling                   |
| **8**     |  Multimodal Summarization and Reward Modeling    | Safety & Ethics                     | Hallucination prevention, jailbreak methods, bias mitigation    |
| **9**     |  AI Research Assistant Capstone Project  | Voice & Multimodal AI               | GPT-4o real-time, ASR/TTS pipelines, chained agents             |
| **10**    |  (See Week 9)   | Final Capstone                      | Agents, MCP protocol, function calling, task chaining           |
