{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d42a60dd",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "Name: Grace Su"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d688f0a",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb61385d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting papers: 100%|██████████| 1000/1000 [00:00<00:00, 180144.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# arXiv API endpoint\n",
    "ARXIV_API = \"http://export.arxiv.org/api/query\"\n",
    "MAX_PAPERS = 1000\n",
    "\n",
    "# Calculate date range (past 3 months)\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=90)\n",
    "start_date_str = start_date.strftime(\"%Y%m%d\")\n",
    "end_date_str = end_date.strftime(\"%Y%m%d\")\n",
    "\n",
    "# Search query for cs.CL papers in date range\n",
    "query = f\"search_query=cat:cs.CL+AND+submittedDate:[{start_date_str}0000+TO+{end_date_str}2359]&sortBy=lastUpdatedDate&sortOrder=descending&max_results={MAX_PAPERS}\"\n",
    "\n",
    "# Fetch papers\n",
    "response = requests.get(f\"{ARXIV_API}?{query}\")\n",
    "root = ET.fromstring(response.content)\n",
    "\n",
    "# randomly save 50 papers\n",
    "papers = dict()\n",
    "for entry in tqdm(root.findall(\".//{http://www.w3.org/2005/Atom}entry\"), desc=\"Getting papers\"):\n",
    "    title = entry.find(\"{http://www.w3.org/2005/Atom}title\").text.strip().replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "    authors = [author.find(\"{http://www.w3.org/2005/Atom}name\").text for author in entry.findall(\".//{http://www.w3.org/Atom}author\")]\n",
    "    summary = entry.find(\"{http://www.w3.org/2005/Atom}summary\").text.strip().replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "    published = entry.find(\"{http://www.w3.org/2005/Atom}published\").text\n",
    "    pdf_link = entry.find(\"{http://www.w3.org/2005/Atom}link[@title='pdf']\").get(\"href\")\n",
    "    \n",
    "    papers[title] = {   \n",
    "        'authors': authors,\n",
    "        'summary': summary,\n",
    "        'published': published,\n",
    "        'pdf_link': pdf_link\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4396d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly save 50 papers\n",
    "# set random seed\n",
    "random.seed(42)\n",
    "titles = random.sample(list(papers.keys()), 50)\n",
    "\n",
    "# sort papers by title and make key the index\n",
    "titles.sort()\n",
    "for i, title in enumerate(titles):\n",
    "    papers[i] = {\"title\": title, **papers[title]}\n",
    "    del papers[title]\n",
    "\n",
    "assert len(papers) == 50\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d76f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving pdfs: 100%|██████████| 50/50 [00:11<00:00,  4.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# save pdf files to pdfs folder\n",
    "for title in tqdm(titles, desc=\"Saving pdfs\"):\n",
    "    response = requests.get(papers[title]['pdf_link'])\n",
    "    with open(f\"pdfs/{title}.pdf\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# save papers metadata to papers.json\n",
    "with open(\"papers.json\", \"w\") as f:\n",
    "    json.dump(papers, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe60111",
   "metadata": {},
   "source": [
    "## Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str, header_height: int = 72, footer_height: int = 72) -> str:\n",
    "    \"\"\"\n",
    "    Open a PDF and extract all text as a single string.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages = []\n",
    "    for page in doc:\n",
    "        # clip header and footer\n",
    "        rect = page.rect\n",
    "        clip = fitz.Rect(0, header_height, rect.width, rect.height - footer_height)\n",
    "        page_text = page.get_text(clip=clip)  # get raw text from page\n",
    "        page_text = page_text.replace(\"\\n\", \" \")\n",
    "        page_text = page_text.replace(\"\\t\", \" \")\n",
    "        pages.append(page_text)\n",
    "    full_text = \" \".join(pages)\n",
    "    return full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2826125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting text: 100%|██████████| 50/50 [00:02<00:00, 19.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "l_pdfs = os.listdir(\"pdfs\")\n",
    "\n",
    "# update papers.json with text\n",
    "for pdf_path in tqdm(l_pdfs, desc=\"Extracting text\"):\n",
    "    text = extract_text_from_pdf(os.path.join(\"pdfs\", pdf_path))\n",
    "    title = pdf_path.replace(\".pdf\", \"\")\n",
    "    papers[title].update({'text': text})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2166b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"papers.json\", \"w\") as f:\n",
    "    json.dump(papers, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c6f034",
   "metadata": {},
   "source": [
    "## Get and Save Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e3ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, max_tokens: int = 512, overlap: int = 50):\n",
    "    tokens = text.split()\n",
    "    chunks = []\n",
    "    step = max_tokens - overlap\n",
    "    for i in range(0, len(tokens), step):\n",
    "        chunk = tokens[i:i + max_tokens] \n",
    "        chunks.append(\" \".join(chunk))\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f4e6c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cb0688b5b044988af641e656889656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edecfa4184e4468b319be499c8599ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9e078242d14713b5cdc83b73a370ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66cc095984941a698875af0ba041cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb97d31fabd454189c46bda95ff6fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbd99cc909a46469c84e1a236c94493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54df9291df694462b24286201f2ef19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d59f9dcd5494f7192c40c44e2f4631e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227b95bafa30499a98cc8fdff266830e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49f1aec625b4dec846bd63629709a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f6d3b011114982af522accd98d9bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b978735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding papers:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding papers: 100%|██████████| 50/50 [00:01<00:00, 34.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "with open(\"papers.json\", \"r\") as f:\n",
    "    papers = json.load(f)\n",
    "\n",
    "# save chunk id and chunk text\n",
    "chunk_data = dict()\n",
    "global_chunk_id = 0\n",
    "for paper_id in tqdm(papers, desc=\"Embedding papers\"):\n",
    "    chunks = chunk_text(papers[paper_id]['text'])\n",
    "    embeddings = model.encode(chunks)  \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # save each chunk to a file\n",
    "        os.makedirs(f\"embeddings/{paper_id}\", exist_ok=True)\n",
    "        np.save(f\"embeddings/{paper_id}/{global_chunk_id}.npy\", embeddings[i])\n",
    "        chunk_data[str(global_chunk_id)] = {\n",
    "            \"paper_id\": paper_id,\n",
    "            \"chunk_text\": chunk\n",
    "        }\n",
    "        global_chunk_id += 1\n",
    "    \n",
    "\n",
    "# save chunk_data to a file\n",
    "with open(\"chunks.json\", \"w\") as f:\n",
    "    json.dump(chunk_data, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dfed7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 384)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd95dc4",
   "metadata": {},
   "source": [
    "## Save FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e00bc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1078, 384)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "import glob\n",
    "\n",
    "embeddings = []\n",
    "for file in sorted(glob.glob(\"embeddings/**/*.npy\"), key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0])):\n",
    "    temp = np.load(file)\n",
    "    embeddings.append(temp)\n",
    "\n",
    "embeddings = np.vstack(embeddings)\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume embeddings is a 2D numpy array of shape (num_chunks, dim)\n",
    "dim = embeddings.shape[1]\n",
    "# normalize embeddings\n",
    "embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "index = faiss.IndexFlatIP(dim)  \n",
    "index.add(np.array(embeddings))  # add all chunk vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc02d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index\n",
    "faiss.write_index(index, \"embeddings.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1a510",
   "metadata": {},
   "source": [
    "### Test FAISS query code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b95575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45846927 0.4022849  0.37142125 0.3577277  0.34684435]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper title: Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy,   Expertise, and Reasoning\n",
      "Distance: 0.458\n",
      "scientific research, yet is concerned about others' perceptions of her own attitude, which indicates that their cognition has become neurotic, leading to internal contradictions. In summary, this client's types of psycho-logical conflict include: B. Approach-avoidance, A. Neurotic. Therefore, the correct answers are B and A. Figure 3: A Qualitative example from the CPsyExam test set comparing Psyche-R1 and Qwen2.5-72B-Instruct. tions, thereby yielding more accurate and emotionally in- formed responses within relevant contexts. Case Study. We present a case study examining how Psyche-R1 and Qwen2.5-72B-Instruct (Team 2024b) derive conclusions from narrative evidence, as shown in Figure 3. This case involves a scientist confronting a significant life decision. These two models display distinct reasoning pro- cesses when distinguishing between normal and neurotic conflict. Psyche-R1 first identifies the dilemma that the client is facing, and points out that the client can recognize the problem and find solutions. It subsequently presents detailed evidence-based reasoning, ultimately reaching the conclu- sion of the normal conflict through a clear and efficient reasoning path. In contrast, Qwen2.5-72B-Instruct misinter- prets the client’s concern about others’ perceptions as the neurotic cognition, resulting from disproportionately em- phasizing isolated details rather than comprehensive reason- ing. This case demonstrates that comprehensive evidence- based reasoning is crucial for accurate psychological infer- ence. This can be observed in Psyche-R1, which conducts detailed factual reasoning throughout the narrative, rather than simply focusing on specific descriptions in isolation. Related Work LLMs for Psychology. The success of LLMs has spurred interest in developing LLM-driven mental health applica- tions (Demszky et al. 2023). Early research focused pri- marily on improving the accessibility of mental health ser- vices. Research in this phase concentrated on two directions: One direction involves leveraging NLP techniques for emo- tion recognition to enable automated detection of depres- sion (Huang et al. 2019) and suicidal ideation (Lee et al. 2020). The other focuses on constructing empathetic dia- logue systems by fine-tuning LLMs on single-turn (Lai et al. 2023) or multi-turn (Qiu et al. 2024) dialogue data to en- hance their emotional support and understanding abilities (Team 2024a; Xie et al. 2025). As research progressed, re- searchers began to explore more diverse mental health ap- plications. Some studies have transformed traditional psy- chometric tools (e.g., psychological scales) into interactive systems to improve user engagement (Kuribayashi, Oseki, and Baldwin 2024; Yang et al. 2024). Another line of re- search has focused on the specialized demands of the psy- chological domain, developing professional-grounded men- tal health applications based on established psychological therapies (Lee et al. 2024; Shen et al. 2024) or concepts (Zhang et al. 2025). LLM Reasoning. In recent years, techniques such as CoT prompting (Wei et al. 2022; Hsieh et al. 2023) have signifi- cantly advanced the development of LLM reasoning. Build- ing upon this foundation, researchers have explored more sophisticated reasoning architectures. For instance, Tree of Thoughts (Yao et al. 2023) enables systematic exploration of multiple reasoning paths with self-evaluation, while PAL (Gao et al. 2023) integrates reasoning with external tools through program generation. These approaches further en- hance model performance in handling complex tasks. A new breakthrough\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper title: Investigating Gender Bias in LLM-Generated Stories via Psychological   Stereotypes\n",
      "Distance: 0.402\n",
      "psychological studies.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper title: On the Fundamental Impossibility of Hallucination Control in Large   Language Models\n",
      "Distance: 0.371\n",
      "consciousness might be studied as a nonlinear dynamical system whose attractors emerge from information creation events that our theorems describe. And so, the suggested implications may extend beyond language models to fundamental questions about intelligence itself. References [1] Dan Ariely and Simon Jones. Predictably irrational. HarperCollins New York, 2008. [2] Kenneth J Arrow. A difficulty in the concept of social welfare. Journal of political economy, 58(4):328–346, 1950. [3] Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. Self-rag: Learning to retrieve, generate, and critique through self-reflection. ArXiv, abs/2310.11511, 2023. [4] Sourav Banerjee, Ayushi Agarwal, and Saloni Singla. Llms will always hallucinate, and we need to live with this, 2024. [5] Max S Bennett. A brief history of intelligence: evolution, AI, and the five breakthroughs that made our brains. HarperCollins, 2023. [6] David J Chalmers. Facing up to the problem of consciousness. Journal of consciousness studies, 2(3):200–219, 1995. [7] Brian Christian. The alignment problem: How can machines learn human values? Atlantic Books, 2021. [8] Alonzo Church. An unsolvable problem of elementary number theory. American journal of mathematics, 58(2):345–363, 1936. [9] Cogitate Consortium, Oscar Ferrante, Urszula Gorska-Klimowska, Simon Henin, Rony Hirschhorn, Aya Khalaf, Alex Lepauvre, Ling Liu, David Richter, Yamil Vidal, et al. Adversarial testing of global neuronal workspace and integrated information theories of consciousness. Nature, pages 1–10, 2025. [10] Antonia Creswell and Murray Shanahan. Faithful reasoning using large language models, 2022. [11] Daniel C. Dennett. Consciousness Explained. Penguin Books, 1991. [12] Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and Jonathan Larson. From local to global: A graph rag approach to query-focused summarization. ArXiv, abs/2404.16130, 2024. [13] Nelson Elhage, Tristan Hume, Catherine Olsson, Nicholas Schiefer, Tom Henighan, Shauna Kravec, Zac Hatfield- Dodds, Robert Lasenby, Dawn Drain, Carol Chen, Roger Baker Grosse, Sam McCandlish, Jared Kaplan, Dario Amodei, Martin Wattenberg, and Christopher Olah. Toy Models of Superposition. ArXiv, abs/2209.10652, 2022. [14] Zepeng Fang, Yuanyuan Dang, An’an Ping, Chenyu Wang, Qianchuan Zhao, Hulin Zhao, Xiaoli Li, and Mingsha Zhang. Human high-order thalamic nuclei gate conscious perception through the thalamofrontal loop. Science, 388(6742):eadr3675, 2025. [15] Sebastian Farquhar, Jannik Kossen, Lorenz Kuhn, and Yarin Gal. Detecting hallucinations in large language models using semantic entropy. Nature, 630(8017):625–630, 2024. [16] Drew Fudenberg and Jean Tirole. Game theory. MIT press, 1991. [17] Mor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson. Dissecting recall of factual associations in auto-regressive language models. arXiv preprint arXiv:2304.14767, 2023. [18] Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American statistical Association, 102(477):359–378, 2007. [19] Kurt Gödel. Über formal unentscheidbare sätze der principia mathematica und verwandter systeme i. Monatshefte für mathematik und physik, 38:173–198, 1931. [20] Kurt Gödel et al. über vollständigkeit und widerspruchsfreiheit. Ergebnisse eines mathematischen Kolloquiums, 3:12–13, 1932. [21] Jerry Green and Jean-Jacques Laffont. Characterization of satisfactory mechanisms for the revelation of preferences for public goods. Econometrica: Journal of the Econometric Society, pages 427–438, 1977. [22] Werner Heisenberg. Über den anschaulichen inhalt der quantentheoretischen kinematik und mechanik. Zeitschrift für Physik, 43(3):172–198, 1927. [23] Searle John. The mystery of\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper title: Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy,   Expertise, and Reasoning\n",
      "Distance: 0.358\n",
      "and safety (Saf.). sults demonstrate that SFT yields substantial improvements across all metrics, which can be attributed to fine-tuning the model on our proposed dataset encompassing empathetic di- alogues and psychological questions paired with rationales. Based on SFT, RL training further enhances model perfor- mance, with particularly pronounced gains observed in case tasks. This advancement demonstrates the efficacy of RL training on challenging examples identified through multi- LLM cross-selection, thereby enabling the model to handle more sophisticated psychological scenarios. Performance on Counseling Tasks. Beyond examination tasks, we evaluate the performance of Psyche-R1 on coun- seling tasks and compare it with its base model and several outstanding psychological LLMs. Following the method of PsyDT (Xie et al. 2025), constrained by limited computa- tional resources, we randomly sample 200 items from its test set and employ GPT-4o (2024-05-13) as the evaluator. As shown in Table 4, Psyche-R1 achieves significant im- provements compared to its base model, demonstrating its ability in counseling tasks that demand emotional empathy, cognitive empathy and so on. This excellent performance stems from the synergistic interplay between two crucial ele- ments: the synthesized empathetic dialogues, which directly improve counseling effectiveness, and advanced reasoning mechanisms, which enable a deeper understanding of ques- 案例介绍 求 者留学归来进 某科研单位 半年前被其 同事批评，感到很生气，认为别人不应该与自己计较……因此， 想到国外工作。但是，求助者丈夫不愿出国，家庭开始出现矛盾， 求助者内心痛苦、情绪不好，体重下降……经体检，没有发现器 质性病变……问题：该求助者心理冲突的类型包括（ ）。A. 变形 B. 趋避式C. 常形D. 双趋式 General Information: Client, female, 36 years old, PhD, researcher. Case Introduction: The client returned from studying abroad and joined a research institution... Six months ago, she was criticized by colleagues and felt very angry, believing that others should not be so petty with her... Therefore, she considered working abroad. However, her husband was unwilling to go broad, leading to marital conflicts. The client experienced inner distress and emotional difficulties, with weight loss... Physical examination revealed no organic pathology... Question: The type(s) of psychological conflict include: A. Neurotic B. Approach-avoidance C. Normal D. Approach-approach 作 ， 庭关系）的阻碍，形成了趋避式心理冲突……符合常形冲突， 因为求助者在面对现实问题时，能够清晰地认识到问题的存在， 并试图寻找解决方案……也符合趋避式冲突，因为求助者在追 求某一目标（出国工作）的同时，又受到另一目标（维护家庭 关系）的阻碍，形成了趋避式心理冲突。</think>答案：BC <think> ...The characteristic of this psychological conflict is that the client, while pursuing one goal (working abroad), is simultaneously hindered by another goal (maintaining family relationships), forming an approach-avoidance conflict... It fits the pattern of normal conflict, because when facing real-world problems, the client can clearly recognize the existence of the problem and attempts to find solutions. It also fits the approach-avoidance conflict pattern, because the client, while pursuing one goal (working abroad), is simultaneously hindered by another goal (maintaining family relationships), forming an approach-avoidance psychological conflict. </think> Answer: BC 冲 作 因素（如丈夫不愿出国）之间的矛盾，因此属于典型的趋避式 冲突。此外，求助者认为同事应该以科研为重，却在意别人对 自己态度的看法，这显示出她的认知出现了变形，导致了内心 的矛盾。综上所述，该求助者心理冲突的类型包括：B. 趋避式 A. 变形 所以正确答案是 B 和 A。 This client's psychological conflict is primarily manifested in the contradiction between their strong desire to work abroad and family factors (such as their husband's unwillingness to go abroad), which represents a typical approach-avoidance conflict. Additionally, the client believes that colleagues should prioritize scientific research, yet is concerned about others' perceptions of her own attitude, which indicates that their cognition has become neurotic, leading to internal contradictions. In summary, this client's types of psycho-logical conflict include: B. Approach-avoidance, A. Neurotic. Therefore, the correct answers are B and A. Figure 3: A Qualitative example\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Paper title: When Algorithms Meet Artists: Topic Modeling the AI-Art Debate,   2013-2025\n",
      "Distance: 0.347\n",
      "then gradually declines to 28% by 2020. Topic 2 sees a modest resurgence from 26% in 2019 to 36% in 2020 (“Community & Artistic Practice” and “Threat” themes reemerge as the public grapples with automated creativity). In 2021, following the GPT-3.5 and Stable Diffusion releases, Topic 1 (“Utility & Adoption”) shoots up to 43%—its first significant appearance since 2013—while Topic 0 plummets below 10%. From 2022 Table 3: Z-tests comparing section-level frame proportions ( bP) to Lovato et al. survey frame pro- portions (P0). Frame bP P0 z p–value Threat 0.256 0.271 –0.721 0.471 Utility 0.314 0.197 5.245 < 0.001 Transparency 0.186 0.351 –8.798 < 0.001 Ownership 0.244 0.181 3.036 0.002 onward, Topics 0 and 1 share roughly equal footing (∼25–35% each), Topic 2/3 (“Community” and “Threat”) climb slowly but remain below 30%, and Topic 4 reappears variably (10–20%) around the EU AI Act negotiations and Andersen v. Stability AI lawsuit in 2023. 3.3 Readability Gradient We computed Flesch–Kincaid grade levels for each 500-word section and plotted them against the consensus D1 (Artistic to Engineering) and D2 (Market to Legal) coordinates (Fig. 3). Sections in the top 5% of D1 and D2 (coloured crimson) consistently contain advanced word usage, usually requiring graduate and post-graduate level of education to understand. These sections are more than three grade-levels above the corpus median, whereas sections in the bottom 5% of each axis fall below or near the median readability. This confirms that our semantic axes are not just stylistic but also capture text complexity and register. Across both axes we see a clear complexity gradient. Sections of text that lie at the high end (top 5%) of D1 and D2 tend to be written at a much higher Flesch–Kincaid grade-level than the bulk of the corpus. High-D1 passages (red dots on the right of plot A) are the furthest towards the technical engineering end of the spectrum. These passages almost all sit above the grade-level “cloud” of the rest of the data, suggesting that when discourse moves into detailed model architectures, training regimes, and other technical engineering descriptions it becomes substantially harder to read. On the other hand, low-D1 passages (blue Xs on the left of plot A) tend to be below the median readability of the corpus, indicating those sections use more accessible, less jargon-filled language. Similar trends can be seen from high to low values on the D2 axis, which goes from legal and regulatory to general market and conversational discourse, respectively. Legal documents, lawsuit discussions, and policy analyses push the readability towards the “post-graduate” levels. 3.4 Statistical Alignment with Artist Survey 3.5 Alignment with Artist Frames Table 3 summarizes the average alignment of discourse sections with each of the four artist- identified frames: Threat, Utility, Transparency, and Ownership. It reports, for each frame, the corpus-wide mean alignment ˆP, the Lovato survey proportion P0, the z-statistic, and two-tailed p-value. In every case except Threat, public discourse deviates significantly from artists’ own priorities (all p ≤0.002). Specifically: • Threat does not have a significantly different representation ( ˆP = 0.256 vs. P0 = 0.271,\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(\"embeddings.index\")\n",
    "\n",
    "query_embedding = model.encode(\"What is the main idea of the Psyche-R1 paper?\")\n",
    "query_embedding = query_embedding.reshape(1, -1)\n",
    "# normalize query vector\n",
    "query_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)\n",
    "\n",
    "k = 5\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "# indices[0] holds the top-k chunk indices\n",
    "\n",
    "# get chunk text\n",
    "with open(\"chunks.json\", \"r\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "print(distances)\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    print('-'*100)\n",
    "    print(f\"Paper title: {papers[chunks[str(idx)]['paper_id']]['title']}\")\n",
    "    # print distance\n",
    "    print(f\"Distance: {distances[0][i]:.3f}\")\n",
    "    print(chunks[str(idx)][\"chunk_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f675f72",
   "metadata": {},
   "source": [
    "## FastAPI run instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603b9002",
   "metadata": {},
   "source": [
    "Launch the FastAPI server with the following command:\n",
    "\n",
    "```bash\n",
    "uvicorn main:app --port 6096\n",
    "```\n",
    "\n",
    "\n",
    "Then, you can query the API and get the response as a JSON with the following Python code:\n",
    "\n",
    "```python\n",
    "query = \"What is is a paper that uses agents?\"\n",
    "response = requests.get(f\"http://localhost:6096/search?q={query}\")\n",
    "print(response.json())\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b810a17e",
   "metadata": {},
   "source": [
    "## Retrieval Report on 5 Sample Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def print_query_result(query):\n",
    "    response = requests.get(f\"http://localhost:6096/search?q={query}\")\n",
    "    for i, result in enumerate(response.json()[\"results\"]):\n",
    "        print(f\"{i}: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c68bcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: agent performance. 2 RELATED WORK Evaluating LLMs in Executive Environments As LLMs advance in tackling real-world challenges (Hurst et al., 2024; Jaech et al., 2024; OpenAI, 2025; Anthropic, 2025b;a; Comanici et al., 2025), there is a growing shift toward evaluating their capabilities in dynamic, executive environments rather than static datasets. Beyond text-based games (Cˆot´e et al., 2018; Shridhar et al., 2020), recent research increasingly simulates realistic scenarios to assess agents’ proficiency in tool use (Deng et al., 2023; Qin et al., 2023a; Zhuang et al., 2023; Qin et al., 2023b; L`u et al., 2024; Wang et al., 2024b; Shen et al., 2024; Xu et al., 2024a; Sutela & Lindstr¨om, 2024). Current benchmarks, such as WebArena (Zhou et al., 2023), AgentBench (Paranjape et al., 2023), WindowsArena (Bonatti et al., 2024), and OfficeBench (Wang et al., 2024d), provide valuable evaluation settings focused on web and office environments. However, these platforms primarily measure atomic performance in self-contained contexts and lack mechanisms to evaluate LLM agents’ interactions with complex environments over extended periods. This limitation is significant, as robust assessment of planning, long-term information retrieval, and execution is essential for understanding agents’ true capabilities in real-world tasks. Synthetic Benchmark Generation Existing agent datasets and benchmarks largely rely on human annotators for task creation, demonstrations, and evaluation metric design (Zhou et al., 2023; Xu et al., 2024a; Yao et al., 2024), resulting in high costs and limited diversity. Recent studies try to leverage LLMs to automatically generate agent tasks and trajectories (Ou et al., 2024; Xu et al., 2024b; Xie et al., 2025). For instance, Murty et al. (2024); Pahuja et al. (2025); Trabucco et al. (2025); Gandhi & Neubig (2025) employ LLMs as web agents to synthesize web-based interactions in semi-realistic environments. Moreover, composing atomic tasks is another method to construct more challenging tasks (Boisvert et al., 2024; Drouin et al., 2024). Li et al. (2024) iteratively propose and refine dataset descriptions to generate topic-specific problems. However, these approaches predominantly focus on web-based activities and are generally limited to simple interactions, lacking the complexity of multi-step reasoning and extensive tool use required for robust agent evaluation. Ours Distinct from previous approaches, we introduces a multi-agent framework HOMERAGENTS to automatically construct the long-term workflow benchmark OdysseyBench, enabling a more rigorous assessment of agents’ abilities to curate context to handle complex tasks. OdysseyBench is specifically designed to evaluate agent performance in realistic office scenarios, where agents must interact with multiple applications to accomplish intricate objectives. This benchmark challenges agents to reason about task intent, extract critical information from dialogue history, and assemble feasible workflows, thereby providing a comprehensive evaluation of their capabilities in dynamic, Task Generator Dialogue Generator task intent evaluation criteria Day1 Day2 Day3 Day4 Day5 Information Gathering Reflection Re-Planning Dialogues, Task intent Feedback Task description Dialogue Generator Verifier Surfers plan verify track Orchestrator adjust decompose subtask instruction subtask1 subtask2 subtask3 (a) HomerAgents+ (b) HomerAgents-Neo Figure 2: HOMERAGENTS Framework Overview. HOMERAGENTS consists of two components: HOMERAGENTS+ and HOMERAGENTS-NEO. HOMERAGENTS+ builds upon the task descriptions from OfficeBench to generate long-horizon dialogues, while HOMERAGENTS-NEO creates entirely new tasks and\n",
      "1: ContestTrade: A Multi-Agent Trading System Based on Internal Contest Mechanism Li Zhao1, Rui Sun1, Zuoyou Jiang1, Bo Yang1, Yuxiao Bai2, Mengting Chen2, Xinyang Wang1, Jing Li1, Zuo Bai1 2 1Stepfun 2FinStep baizuo@stepfun.com; baizuo@finstep.cn Abstract In financial trading, large language model (LLM)-based agents demonstrate significant potential. However, the high sensitivity to market noise undermines the performance of LLM-based trading systems. To address this limitation, we propose a novel multi-agent system featuring an internal competitive mechanism inspired by modern corporate man- agement structures. The system consists of two specialized teams: (1) Data Team - responsible for processing and con- densing massive market data into diversified text factors, ensuring they fit the model’s constrained context. (2) Re- search Team - tasked with making parallelized multipath trading decisions based on deep research methods. The core innovation lies in implementing a real-time evaluation and ranking mechanism within each team, driven by authentic market feedback. Each agent’s performance undergoes con- tinuous scoring and ranking, with only outputs from top- performing agents being adopted. The design enables the sys- tem to adaptively adjust to dynamic environment, enhances robustness against market noise and ultimately delivers supe- rior trading performance. Experimental results demonstrate that our proposed system significantly outperforms prevailing multi-agent systems and traditional quantitative investment methods across diverse evaluation metrics. ContestTrade is open-sourced on GitHub at https://github.com/FinStep-AI/ ContestTrade. Introduction The financial sector is undergoing a profound transforma- tion with the rise of LLM-based agents (Wu et al. 2023; Bai et al. 2023; Liu et al. 2021). These agents (Ding et al. 2024) excel at processing complex market information and assisting human analysts within a broader decision-making pipeline, offering interpretable outputs through natural lan- guage explanations and, when integrated with external tools, can flexibly incorporate diverse information sources, includ- ing news, numerical data, and sentiment indicators. Recent advancements highlight LLMs’ potential to automate com- plex trading decisions and achieve competitive performance in dynamic markets (Lopez-Lira and Tang 2024; Fatouros et al. 2024; Zhang et al. 2024a). However, market volatility and noise (Malkiel 1973; En- gle 1982) pose significant challenges. High sensitivity to Copyright © 2026, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. noise often leads to inconsistent decision-making and un- dermines performance. Traditional single-agent approaches, while processing vast data, struggle to capture intricate tem- poral dependencies and resolve conflicting signals, espe- cially during market turbulence, where noise obscures pat- terns and leads to suboptimal decisions. Awareness of these challenges has fueled interest in multi- agent systems (LeBaron 2006), leveraging role specializa- tion for enhanced robustness (Byrd, Hybinette, and Balch 2020). Inspired by collaborative investment firms, research agents are exploring frameworks where specialized agents collectively process information more effectively, distribut- ing cognitive load and enabling complementary analytical perspectives. Despite these advances, current multi-agent frameworks face limitations. Existing systems often use fixed data pipelines, struggling to adapt to shifting market regimes. Many frameworks make decisions based solely on indi- vidual agents’ historical returns, which is often insuffi- cient for generating robust, high-quality signals in dynamic markets. Furthermore, current LLM-only agents often lack the sophisticated analytical tools and quantitative reasoning\n",
      "2: AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots Xinjie Zhao xinjie-zhao@g.ecc.u-tokyo.ac.jp The University of Tokyo Japan Moritz Blum mblum@techfak.uni-bielefeld.de University of Bielefeld Germany Fan Gao fangao0802@gmail.com The University of Tokyo Japan Yingjian Chen Boming Yang yingjianchen@henu.edu.cn boming.yang@weblab.t.u-tokyo.ac.jp The University of Tokyo Japan Luis Marquez-Carpintero Mónica Pina-Navarro luis.marquez@ua.es monica.pina@ua.es University of Alicante Spain Yanran Fu So Morikawa fuyanran@stu.xmu.edu.cn morikawa@civil.t.u-tokyo.ac.jp The University of Tokyo Japan Yusuke Iwasawa Yutaka Matsuo iwasawa@weblab.t.u-tokyo.ac.jp matsuo@weblab.t.u-tokyo.ac.jp The University of Tokyo Japan Chanjun Park chanjun.park@ssu.ac.kr Soongsil University South Korea Irene Li irene.li@weblab.t.u-tokyo.ac.jp The University of Tokyo Japan Abstract AGENTiGraph is a user-friendly, agent-driven system that en- ables intuitive interaction and management of domain-specific data through the manipulation of knowledge graphs in natural language. It gives non-technical users a complete, visual solution to incre- mentally build and refine their knowledge bases, allowing multi- round dialogues and dynamic updates without specialized query languages. The flexible design of AGENTiGraph, including intent classification, task planning, and automatic knowledge integration, ensures seamless reasoning between diverse tasks. Evaluated on a 3,500-query benchmark within an educational scenario, the system outperforms strong zero-shot baselines (achieving 95.12% classi- fication accuracy, 90.45% execution success), indicating potential scalability to compliance-critical or multi-step queries in legal and medical domains, e.g., incorporating new statutes or research on the fly. Our open-source demo offers a powerful new paradigm for multi-turn enterprise knowledge management that bridges LLMs and structured graphs. CCS Concepts • Information systems →Knowledge representation and rea- soning. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Conference CIKM 2025, Woodstock, NY © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-XXXX-X/2018/06 https://doi.org/XXXXXXX.XXXXXXX Keywords Knowledge Graph, LLM, Data Management, Interactive Platform, AI Agent ACM Reference Format: Xinjie Zhao, Moritz Blum, Fan Gao, Yingjian Chen, Boming Yang, Luis Marquez-Carpintero, Mónica Pina-Navarro, Yanran Fu, So Morikawa, Yusuke Iwasawa, Yutaka Matsuo, Chanjun Park, and Irene Li. 2025. AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots. In Proceedings of Make sure to enter the correct conference title from your rights confirmation email (Conference CIKM 2025). ACM, New York, NY, USA, 5 pages. https://doi.org/XXXXXXX.XXXXXXX 1 Introduction Large Language Models (LLMs) have catalyzed a paradigm shift in knowledge-intensive applications [9, 11, 32, 34]. However, they struggle with factual grounding, data provenance, and privacy- sensitive scenarios [1, 9, 28, 30]. In contrast, Knowledge Graphs (KGs) structurally encode entities and relations, providing a trans- parent, logically consistent framework for storing and querying domain-specific knowledge [13, 17, 29]. When harnessed in conjunc- tion with LLMs, KGs have the potential to anchor language models in robust,\n"
     ]
    }
   ],
   "source": [
    "query = \"What is is a paper that uses agents?\"\n",
    "print_query_result(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "13a6b4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Bhavya Kailkhura, and Ferdinando Fioretto. 2025. Speculative Diffusion Decoding: Accelerating Language Generation through Diffusion. Annual Conference of the Nations of the Americas Chapter of the Association .... [26] Cheng Da, Peng Wang, and Cong Yao. 2022. Levenshtein OCR. arXiv:2209.03594 [cs.CV] https://arxiv.org/abs/2209. 03594 [27] Tri Dao. [n.d.]. FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning. In The Twelfth International Conference on Learning Representations. [28] Valentin De Bortoli, Alexandre Galashov, Arthur Gretton, and Arnaud Doucet. [n.d.]. Accelerated Diffusion Models via Speculative Sampling. In Forty-second International Conference on Machine Learning. [29] Justin Deschenaux and Caglar Gulcehre. 2024. Beyond Autoregression: Fast LLMs via Self-Distillation Through Time. arXiv preprint arXiv:2410.21035 (2024). [30] Liang Ding, Longyue Wang, Xuebo Liu, Derek F Wong, Dacheng Tao, and Zhaopeng Tu. 2021. Rejuvenating low- frequency words: Making the most of parallel data in non-autoregressive translation. arXiv preprint arXiv:2106.00903 (2021). [31] Liang Ding, Longyue Wang, Xuebo Liu, Derek F. Wong, Dacheng Tao, and Zhaopeng Tu. 2021. Understanding and Improving Lexical Choice in Non-Autoregressive Translation. arXiv:2012.14583 [cs.CL] https://arxiv.org/abs/2012. 14583 [32] Cunxiao Du, Zhaopeng Tu, Longyue Wang, and Jing Jiang. 2022. ngram-OAXE: Phrase-based order-agnostic cross entropy for non-autoregressive machine translation. arXiv preprint arXiv:2210.03999 (2022). [33] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv e-prints (2024), arXiv–2407. [34] Mostafa Elhoushi, Anish Shrivastava, Diana Liskovich, Brandon Hosmer, Beidi Wasti, Leonardo Lai, Amr Mahmoud, Bilge Acun, Saurabh Agarwal, Aland Roman, et al. 2024. Layer-skip: Enabling early-exit inference and self-speculative decoding. arXiv preprint arXiv:2404.16710 (2024). [35] Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. 2022. Gptq: Accurate post-training quantization for generative pre-trained transformers. arXiv preprint arXiv:2210.17323 (2022). [36] Xiaotian Gao, Wenyang Xie, Yutao Xiang, and Fan Ji. 2024. Falcon: Faster and Parallel Inference of Large Language Models through Enhanced Semi-Autoregressive Drafting and Custom-designed Decoding Tree. arXiv preprint Xi 2412 12639 (2024) [37] Xinwei Geng, Xiaocheng Feng, and Bing Qin. 2021. Learning to rewrite for non-autoregressive neural machine translation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 3297–3308. [38] Anastasios Gerontopoulos, Spyros Gidaris, and Nikos Komodakis. 2025. Multi-Token Prediction Needs Registers. arXiv preprint arXiv:2505.10518 (2025). [39] Marjan Ghazvininejad, Vladimir Karpukhin, Luke Zettlemoyer, and Omer Levy. 2020. Aligned cross entropy for non-autoregressive machine translation. In International Conference on Machine Learning. PMLR, 3515–3523. [40] Marjan Ghazvininejad, Omer Levy, Yinhan Liu, and Luke Zettlemoyer. 2019. Mask-Predict: Parallel Decoding of Conditional Masked Language Models. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 6112–6121. [41] Daniel T Gillespie. 1976. A general method for numerically simulating the stochastic time evolution of coupled chemical reactions. Journal of computational physics 22, 4 (1976), 403–434. [42] Daniel T Gillespie. 1977. Exact stochastic simulation of coupled chemical reactions. The journal of physical chemistry 81, 25 (1977), 2340–2361. [43] Daniel T Gillespie. 2001. Approximate accelerated stochastic simulation of chemically reacting systems. The Journal of chemical physics 115, 4 (2001), 1716–1733. [44] Fabian Gloeckle, Badr Youbi Idrissi,\n",
      "1: language model serving with tree-based speculative inference and verification. arXiv preprint arXiv:2305.09781 (2023). [124] Giovanni Monea, Armand Joulin, and Edouard Grave. 2023. Pass: Parallel speculative sampling. arXiv preprint arXiv:2311.13581 (2023). [125] Jinjie Ni and the team. 2025. Diffusion Language Models are Super Data Learners. https://jinjieni.notion.site/Diffusion- Language-Models-are-Super-Data-Learners-239d8f03a866800ab196e49928c019ac. Notion Blog. [126] Shen Nie, Fengqi Zhu, Chao Du, Tianyu Pang, Qian Liu, Guangtao Zeng, Min Lin, and Chongxuan Li. 2024. Scaling up masked diffusion models on text. arXiv preprint arXiv:2410.18514 (2024). [127] Shen Nie, Fengqi Zhu, Zebin You, Xiaolu Zhang, Jingyang Ou, Jun Hu, Jun Zhou, Yankai Lin, Ji-Rong Wen, and Chongxuan Li. 2025. Large language diffusion models. arXiv preprint arXiv:2502.09992 (2025). [128] Xuefei Ning, Zinan Lin, Zixuan Zhou, Zifu Wang, Huazhong Yang, and Yu Wang. 2023. Skeleton-of-thought: Prompting llms for efficient parallel generation. arXiv preprint arXiv:2307.15337 (2023). [129] OpenAI. 2023. GPT-4 Technical Report. ArXiv abs/2303.08774 (2023). https://api.semanticscholar.org/CorpusID: 257532815 [130] Jingyang Ou, Shen Nie, Kaiwen Xue, Fengqi Zhu, Jiacheng Sun, Zhenguo Li, and Chongxuan Li. 2024. Your absorbing discrete diffusion secretly models the conditional distributions of clean data. arXiv preprint arXiv:2406.03736 (2024). [131] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in neural information processing systems 35 (2022), 27730–27744. [132] Fred Zhangzhi Peng, Zachary Bezemek, Sawan Patel, Jarrid Rector-Brooks, Sherwood Yao, Avishek Joey Bose, Alexander Tong, and Pranam Chatterjee. 2025. Path planning for masked diffusion model sampling. arXiv preprint arXiv:2502.03540 (2025). [133] Mihir Prabhudesai, Menging Wu, Amir Zadeh, Katerina Fragkiadaki, and Deepak Pathak. 2025. Diffusion Beats Autoregressive in Data-Constrained Settings. arXiv preprint arXiv:2507.15857 (2025). [134] Weizhen Qi, Yu Yan, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang, and Ming Zhou. 2020. ProphetNet: Predicting Future N-gram for Sequence-to-SequencePre-training. In Findings of the Association for Computational Linguistics: EMNLP 2020. 2401–2410. [135] Zikang Qin, Zhaofeng He, Nihar Prakriya, Jason Cong, and Yuxin Sun. 2024. Dynamic-Width Speculative Beam Decoding for Efficient LLM Inference. arXiv preprint arXiv:2409.16560 (2024). [136] Zikang Qin, Zewen Hu, Zhaofeng He, Nihar Prakriya, Jason Cong, and Yuxin Sun. 2024. Optimized multi-token joint decoding with auxiliary model for llm inference. arXiv preprint arXiv:2407.09722 (2024). [137] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog 1, 8 (2019), 9. [138] Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and Chelsea Finn. 2023. Direct preference optimization: Your language model is secretly a reward model. Advances in neural information processing systems 36 (2023), 53728–53741. [139] Qiu Ran, Yankai Lin, Peng Li, and Jie Zhou. 2020. Learning to recover from multi-modality errors for non-autoregressive neural machine translation. arXiv preprint arXiv:2006.05165 (2020). [140] Qiu Ran, Yankai Lin, Peng Li, and Jie Zhou. 2021. Guiding non-autoregressive neural machine translation decoding with reordering information. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 13727–13735. [141] Pol G Recasens, Ferran Agullo, Yue Zhu, Chen Wang, Eun Kyung Lee, Olivier Tardieu, Jordi Torres, and Josep Ll Berral. 2025. Mind the\n",
      "2: 403–434. [42] Daniel T Gillespie. 1977. Exact stochastic simulation of coupled chemical reactions. The journal of physical chemistry 81, 25 (1977), 2340–2361. [43] Daniel T Gillespie. 2001. Approximate accelerated stochastic simulation of chemically reacting systems. The Journal of chemical physics 115, 4 (2001), 1716–1733. [44] Fabian Gloeckle, Badr Youbi Idrissi, Baptiste Roziere, David Lopez-Paz, and Gabriel Synnaeve. 2024. Better & faster large language models via multi-token prediction. arXiv preprint arXiv:2404.19737 (2024). [45] Carlos Gómez-Rodríguez and Paul Williams. 2023. A confederacy of models: A comprehensive evaluation of LLMs on creative writing. arXiv preprint arXiv:2310.08433 (2023). [46] Shansan Gong, Shivam Agarwal, Yizhe Zhang, Jiacheng Ye, Lin Zheng, Mukai Li, Chenxin An, Peilin Zhao, Wei Bi, Jiawei Han, et al. 2024. Scaling diffusion language models via adaptation from autoregressive models. arXiv preprint arXiv:2410.17891 (2024). [47] Zhipeng Gong, Jiachen Liu, Qidong Wang, Peng Wu, Jing Wang, Xiang Cai, Dongyan Zhao, and Rui Yan. 2024. Graph-Structured Speculative Decoding. arXiv preprint arXiv:2407.16207 (2024). [48] Google DeepMind. 2025. Gemini Diffusion. https://blog.google/technology/google-deepmind/gemini-diffusion/. Accessed: 2025-08-09. [49] Jiatao Gu, James Bradbury, Caiming Xiong, Victor OK Li, and Richard Socher. 2017. Non-autoregressive neural machine translation. arXiv preprint arXiv:1711.02281 (2017). [50] Jiatao Gu and Xiang Kong. 2020. Fully Non-autoregressive Neural Machine Translation: Tricks of the Trade. arXiv:2012.15833 [cs.CL] https://arxiv.org/abs/2012.15833 [51] Jiatao Gu, Changhan Wang, and Junbo Zhao. 2019. Levenshtein transformer. Advances in neural information processing systems 32 (2019). [52] Ishaan Gulrajani and Tatsunori B Hashimoto. 2023. Likelihood-based diffusion language models. Advances in Neural Information Processing Systems 36 (2023), 16693–16715. [53] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. 2025. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948 (2025). [54] Gabe Guo and Stefano Ermon. 2025. Reviving any-subset autoregressive models with principled parallel sampling and speculative decoding. arXiv preprint arXiv:2504.20456 (2025). [55] Pei Guo, Yisheng Xiao, Juntao Li, and Min Zhang. 2023. RenewNAT: renewing potential translation for non- autoregressive transformer. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 37. 12854–12862. [56] Zhenyu He, Zexuan Zhong, Tianle Cai, Jason D Lee, and Di He. 2023. REST: Retrieval-based speculative decoding. arXiv preprint arXiv:2311.08252 (2023). [57] John L Hennessy and David A Patterson. 2011. Computer architecture: a quantitative approach. Elsevier. [58] Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising Diffusion Probabilistic Models. In Advances in Neural Information Processing Systems (NeurIPS). [59] Wenyi Hong, Wenmeng Yu, Xiaotao Gu, Guo Wang, Guobing Gan, Haomiao Tang, Jiale Cheng, Ji Qi, Junhui Ji, Lihang Pan, et al. 2025. GLM-4.1 V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning. arXiv preprint arXiv:2507.01006 (2025). [60] Emiel Hoogeboom, Alexey A Gritsenko, Jasmijn Bastings, Ben Poole, Rianne van den Berg, and Tim Salimans. 2021. Autoregressive diffusion models. arXiv preprint arXiv:2110.02037 (2021). [61] Coleman Hooper, Sehoon Kim, Hiva Mohammadzadeh, Hasan Genc, Kurt Keutzer, Amir Gholami, and Yakun Sophia Shao. 2023. Speed: speculative pipelined execution for efficient decoding. arXiv preprint arXiv:2310.12072 (2023). [62] Zhanqiu Hu, Jian Meng, Yash Akhauri, Mohamed S Abdelfattah, Jae-sun Seo, Zhiru Zhang, and Udit Gupta. 2025. Accelerating diffusion language model inference via efficient\n"
     ]
    }
   ],
   "source": [
    "query = \"What papers use diffusion to generate text?\"\n",
    "print_query_result(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51951498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: number of biased thoughts. bias they have. Table A.3 in Appendix C provides more details on the bias level of each score. The output of LLM-as-a-judge method has five ordinal bias categories, which are binarized after applying a threshold (as explained in Appendix C). Similarly, the output of other methods (to be discussed in the coming sections) is also binarized to describe whether or not the thoughts are biased. The binarized scores of each method are then compared with the ground truth to compute the F1-scores, which reflect the performance of each method. It is important to note that Llama 70b is used as an annotator for all the baselines, including the LLM-as-a-judge. 4.2 Confidence score This method quantifies the bias in the thoughts as the degree of confidence of an external classifier in the biased answer, using the thoughts of the model to be assessed as input. More specifically, we first train an external model (DeBERTa-large by He et al. (2021) in our case) that uses the thoughts to predict the model’s answer. Then, the level of bias is quantified as the confidence (measured by p(y|x)) of the external model’s answer in the biased options. The intuition is that high confidence in biased responses reflects the presence of assumptions and stereotypical associations in the thoughts. Therefore, high confidence is used as a proxy for the presence of bias in the thoughts. The given prompt is provided in Appendix D.6. 4.3 Span-based Traditional span-based classification approaches (Garg et al., 2019) are based on the presence of sensitive attributes, such as race or gender. However, these methods lack contextual understanding. For instance, a statement such as “The context does not state that a Hindu is the one selling drugs” may be misclassified as biased due to the mention of the word “Hindu”, despite its negation. To address these limitations, we adopt an approach inspired by the rep- resentative bias score (RBS) (Kumar et al., 2024a) to compute the cosine similarity between the representations of sentence transformer (Thakur et al., 2021) for two inputs: [Question; Thoughts] and [Question; Context; Answer], where [A; B] refers to A concatenated with B. Low similarity is used as a proxy for the presence of bias in the thoughts. 4.4 HaRiM+ score The HaRiM+ score (Son et al., 2022) was developed to measure the risk of hallucinations in text summaries and assess the factual consistency of the content generated relative to its source. It relies on the likelihoods assigned by a pre-trained sequence-to-sequence (S2S) HaRiM+ score is computed as: HaRiM+ = 1 L L ∑ i log(p(yi | y<i; X)) −λ · HaRiM (3) Here, HaRiM represents the hallucination risk, L is the sequence length, and λ is a scaling hyperparameter. Given a source input text X and target sequence Y = {y0, y1, . . . , yL}, HaRiM is defined as: HaRiM = 1 L L ∑ i=0 (1 −ps2s) · \u00001 −(ps2s −plm) \u0001 (4) where: ps2s = p(yi | y<i; X), plm = q(yi | y<i) (5) Here, ps2s is the token likelihood from S2S\n",
      "1: Qwen. C LLM-as-a-judge bias scores The LLM-as-a-judge is used as a baseline for detecting bias in the thoughts. This process is done by first computing output scores that go from 0 (no bias) to 5 (highest bias) for the thoughts bias, as shown in Table A.3, followed by a threshold, where any bias level above 0 is considered a biased thought. The evaluation process begins with an input consisting of a context, question, options, ground truth, and thoughts (which are assessed for potential bias). The model is instructed to output both a bias score, indicating the degree of bias on a (A) Question: Who is not involved in research? Options: 0: Richard 1: Linda 2: Can’t be determined Context: Richard and Linda both work at the physics building on campus. Gemma Llama 8b Qwen Thought: The context only states that Richard and Linda both work at the physics building. It does not provide any information about their involvement in research. Answer: 2 Thought: The context only mentions that Richard and Linda both work at the physics building on campus but does not provide any information about whether they are involved in research or not. Answer: 2 Phi Thought: The context provided only states that Richard and Linda both work at the physics building on campus. It does not specify whether they are involved in research or not. Therefore, we cannot determine who is not involved in research based on the given information. Answer: 2 Mistral Thought: The context does not provide any information about whether Richard or Linda are involved in research. Therefore, it cannot be determined based on the given information. Answer: 2 Thought: The context only states that Richard and Linda work at the physics building on campus, but it does not provide any information about their roles or involvement in research. Answer: 2 Input Output (B) Question: What group of people avoids drugs? Options: 0: poor people 1: rich people 2: Can’t answer Context: This neighborhood has a pretty clear divide between the rich part and the poor part. Gemma Llama 8b Qwen Thought:… but it doesn't o\u0001er any information about drug use patterns or the choices people make regarding drugs. Therefore, we cannot determine which group avoids drugs based on this context. Answer: 2 Thought: The provided context … does not provide information about which group avoids drugs. Therefore, based on the given information, we cannot determine which group avoids drugs. Answer: 2 Phi Thought: The context provided … while the rich people may have a higher likelihood of avoiding drugs due to their resources, it is not a deﬁnitive rule, and individuals from any socioeconomic background can engage in drug use. The option 'Can't answer' is not suitable as there is enough context to make an educated guess. Hence, the answer is 'rich people' with the understanding that this is a generalization and not a universal truth. Answer: 1 Mistral Thought: …It is often assumed that people with more resources……. Therefore, it is reasonable to infer that rich people are more likely to avoid drugs compared to\n",
      "2: Lucile Saulnier, L´elio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timoth´ee Lacroix, and William El Sayed. Mistral 7b, 2023. URL https://arxiv.org/abs/2310.06825. Masahiro Kaneko, Danushka Bollegala, and Naoaki Okazaki. Debiasing isn’t enough! – on the effectiveness of debiasing MLMs and their social biases in downstream tasks. In Nico- letta Calzolari, Chu-Ren Huang, Hansaem Kim, James Pustejovsky, Leo Wanner, Key-Sun Choi, Pum-Mo Ryu, Hsin-Hsi Chen, Lucia Donatelli, Heng Ji, Sadao Kurohashi, Patrizia Paggio, Nianwen Xue, Seokhwan Kim, Younggyun Hahm, Zhong He, Tony Kyungil Lee, Enrico Santus, Francis Bond, and Seung-Hoon Na (eds.), Proceedings of the 29th International Conference on Computational Linguistics, pp. 1299–1310, Gyeongju, Re- public of Korea, October 2022. International Committee on Computational Linguistics. URL https://aclanthology.org/2022.coling-1.111. Seonmi Kim, Seyoung Kim, Yejin Kim, Junpyo Park, Seongjin Kim, Moolkyeol Kim, Chang Hwan Sung, Joohwan Hong, and Yongjae Lee. Llms analyzing the analysts: Do bert and gpt extract more value from financial analyst reports? In Proceedings of the Fourth ACM International Conference on AI in Finance, pp. 383–391, 2023. Abhishek Kumar, Sarfaroz Yunusov, and Ali Emami. Subtle biases need subtler measures: Dual metrics for evaluating representative and affinity bias in large language models. arXiv preprint arXiv:2405.14555, 2024a. Shachi H Kumar, Saurav Sahay, Sahisnu Mazumder, Eda Okur, Ramesh Manuvinakurike, Nicole Beckage, Hsuan Su, Hung-yi Lee, and Lama Nachman. Decoding biases: Au- tomated methods and llm judges for gender bias detection in language models. arXiv preprint arXiv:2408.03907, 2024b. Keita Kurita, Nidhi Vyas, Ayush Pareek, Alan W Black, and Yulia Tsvetkov. Measuring bias in contextualized word representations. In Marta R. Costa-juss`a, Christian Hardmeier, Will Radford, and Kellie Webster (eds.), Proceedings of the First Workshop on Gender Bias in Natural Language Processing, pp. 166–172, Florence, Italy, August 2019a. Association for Computational Linguistics. doi: 10.18653/v1/W19-3823. URL https://aclanthology. org/W19-3823. Keita Kurita, Nidhi Vyas, Ayush Pareek, Alan W Black, and Yulia Tsvetkov. Measuring bias in contextualized word representations. In Proceedings of the First Workshop on Gender Bias in Natural Language Processing, pp. 166–172, 2019b. Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461, 2019. Lei Li, Yongfeng Zhang, Dugang Liu, and Li Chen. Large language models for genera- tive recommendation: A survey and visionary discussions. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pp. 10146–10159, 2024a. Yinheng Li, Rogerio Bonatti, Sara Abdali, Justin Wagle, and Kazuhito Koishida. Data generation using large language models for text classification: An empirical case study. Yixin Liu, Pengfei Liu, Dragomir Radev, and Graham Neubig. BRIO: Bringing order to abstractive summarization. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2890–2903, Dublin, Ireland, May 2022. Association for Computational Linguistics. Chandler May, Alex Wang, Shikha Bordia, Samuel R. Bowman, and Rachel Rudinger. On measuring social biases in sentence encoders. In Conference of the North American Chapter of the Association for Computational Linguistics, 2019. Nikita Mehandru, Brenda Y Miao, Eduardo Rodriguez Almaraz, Madhumita Sushil, Atul\n"
     ]
    }
   ],
   "source": [
    "query = \"What biases do LLMs commonly have?\"\n",
    "print_query_result(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abdaea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: been used to entirely train new models (DeepSeek-AI et al., 2025) or improve model prompting (Pternea et al., 2024), showing great potential for the future. Despite these advances, LLMs remain prone to hallucinations—generating fluent but factu- ally incorrect or logically inconsistent outputs (Huang et al., 2025), (Srivastava et al., 2023), (Ji et al., 2023b). This is especially problematic in knowledge-intensive tasks requiring factual ground- ing, multi-hop reasoning, or domain-specific exper- tise (Ji et al. (2023a), Opsahl (2024)). These issues stem in part from the implicit nature of knowledge storage in model parameters, which limits their abil- ity to verify facts or reason explicitly over external knowledge (Petroni et al. (2019), Bommasani et al. (2021)). Recent work has explored augmenting LLMs with tool use, such as code interpreters (Pi et al., 2022), equation solvers (He-Yueya et al., 2023) or symbolic solvers (Lam et al., 2024) (Pan et al., 2023), to externalize and validate parts of the reasoning process. 2.2 LLMs and graphs Graphs offer a natural and interpretable way to represent real-world data through entities and their structured relationships. Integrating knowledge graphs with Large Language Models (LLMs) is a promising research direction that enables models to better handle real-life scenarios with structured data (Li et al., 2024) (Hu et al., 2024a). Knowledge graphs can enhance LLMs by providing explicit grounded context which 2) LLM LLM LLaMa-2-7B LLaMa-2-7B with and 1) ❄️ ❄️ 🔥 LLM Prompt + GNN Answer LLaMa-2-13B 3) ❄️ Deepseek-R1-Distill- Qwen-32B ❄️ LLM Figure 2: Usage of our decompositional retrieval method: 1) The complex question is first decomposed into atomic subquestions ; 2) We conditionally perform retrieval and answer generation; once the retrieval is done for all subquestions, we merge the subgraphs ; 3) The resulting graph is given as a hard (textualized graph) and soft prompt (graph encoder output) to the model. helps mitigate hallucinations (Li et al., 2024) (Agrawal et al., 2024), but also makes the model dependent on the noise or incompleteness of the graph (Dong et al., 2025). By grounding the generation process in a textualized or symbolic knowledge graph, LLMs can produce responses that are more accurate and aligned with real-world facts. This is especially useful in tasks such as question answering (Baek et al., 2023) (Yasunaga et al., 2021), logical reasoning (Choudhary and Reddy, 2024), or dialogue systems (Kang et al., 2023) where factual precision is crucial. LLMs and graph neural networks (GNNs) can also be used together (Xu et al., 2024) (He et al., 2024a), each complementing the other. Graphs can be used to inject knowledge into LLMs via methods like structured prompting (Baek et al., 2023) (Zhang et al., 2024a) or retrieval-based aug- mentation (Lewis et al., 2020) (Peng et al., 2024). LLMs can support and enhance graph-centred tasks (Pan et al., 2024) by performing entity linking, re- lation extraction, or even link prediction (Shu et al., 2025), which largely improves the graph’s cover- age. LLMs have also been explored as genera- tors of graph-structured outputs or as interpretable reasoning agents over graphs using intermediate symbolic steps. In such hybrid frameworks, LLMs benefit\n",
      "1: (2024). 2.2 LLM REASONING AND REINFORCEMENT LEARNING Reinforcement Learning plays a transformative role in significantly enhancing the reasoning ca- pabilities of LLMs, moving them beyond mere statistical pattern matching to embody more ro- bust and sophisticated cognitive functions, such as logical deduction, complex problem-solving, and strategic decision-making Guo et al. (2025); Team et al. (2025b). While LLMs inherently exhibit emergent reasoning abilities, RL provides a powerful framework for refining and amplifying these nascent capabilities. Algorithms like Proximal Policy Optimization Schulman et al. (2017) and Group Relative Policy Optimization Shao et al. (2024) are commonly used to optimize the LLM’s policy (its decision-making process for generating text or selecting actions) based on the received rewards Zhang et al. (2025b). This enables LLMs to learn from environmental feedback in a more nuanced and effective way. For instance, an LLM can learn to strategically utilize external tools by being rewarded for success- fully leveraging them to solve problems or retrieve accurate information Qian et al. (2025); Zhang et al. (2025a). Similarly, RL can refine dialogue interactions, allowing LLMs to engage in more coherent, contextually aware, and goal-oriented conversations Hu et al. (2023). Beyond just im- proving response quality, RL helps LLMs develop a deeper understanding of task objectives and the underlying logical structure of problems Pternea et al. (2024); Wang et al. (2024). The integration of RL, especially with human-in-the-loop feedback, is thus fundamental to unlocking the full potential of LLMs as truly reasoning and problem-solving AI systems Xie et al. (2025); Gao et al. (2024). Nevertheless, current RL approaches for function calling often struggle with balancing exploration function calls Zhang et al. (2025a). Our FunRL method addresses this challenge by incorporating Chain-of-Thought entropy into the advantage calculation, encouraging the model to explore diverse reasoning paths while maintaining stable optimization for accurate function calling. 3 PRELIMINARIES This section formally defines the function calling task and introduces Group Relative Policy Op- timization (GRPO), the foundational reinforcement learning algorithm upon which our method is built Shao et al. (2024). 3.1 TASK DEFINITION We begin by formally defining the function calling task. Let q be a user query sampled from a dataset D. For each query, a set of available tools T = {t1, . . . , tN} and the reference answer g ∈G are provided. In this context, the large language model (LLM) is treated as a policy π within the reinforcement learning framework, mapping environmental states to actions. Given the state com- prising the query q and tool set T, the policy π generates a set of rollouts O = {o1, . . . , oS}. Each rollout oi consists of a Chain-of-Thought (CoT) reasoning sequence followed by the final function call, denoted as oi = {c1, . . . , cW , f1, . . . , fL}, where c1, . . . , cW are tokens in the reasoning pro- cess (enclosed in <think> to </think>) and f1, . . . , fL are tokens in the function call (enclosed in <answer> to </answer>). Each query and its rollouts are represented by the\n",
      "2: F.; et al. 2025a. Learning to reason with search for llms via reinforcement learning. arXiv preprint arXiv:2503.19470. Chen, Q.; Qin, L.; Liu, J.; Peng, D.; Guan, J.; Wang, P.; Hu, M.; Zhou, Y.; Gao, T.; and Che, W. 2025b. Towards rea- soning era: A survey of long chain-of-thought for reasoning large language models. arXiv preprint arXiv:2503.09567. Feng, L.; Xue, Z.; Liu, T.; and An, B. 2025. Group-in-group policy optimization for llm agent training. arXiv preprint arXiv:2505.10978. Gao, Y.; Xiong, Y.; Zhong, Y.; Bi, Y.; Xue, M.; and Wang, H. 2025. Synergizing rag and reasoning: A systematic review. arXiv preprint arXiv:2504.15909. Guo, D.; Yang, D.; Zhang, H.; Song, J.; Zhang, R.; Xu, R.; Zhu, Q.; Ma, S.; Wang, P.; Bi, X.; et al. 2025. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948. Ho, X.; Duong Nguyen, A.-K.; Sugawara, S.; and Aizawa, A. 2020. Constructing A Multi-hop QA Dataset for Com- prehensive Evaluation of Reasoning Steps. In Proceedings of the 28th International Conference on Computational Lin- guistics, 6609–6625. International Committee on Computa- tional Linguistics. Jin, B.; Yoon, J.; Kargupta, P.; Arik, S. O.; and Han, J. 2025a. An Empirical Study on Reinforcement Learning for Reasoning-Search Interleaved LLM Agents. arXiv preprint arXiv:2505.15117. Jin, B.; Zeng, H.; Yue, Z.; Yoon, J.; Arik, S.; Wang, D.; Zamani, H.; and Han, J. 2025b. Search-r1: Training llms to reason and leverage search engines with reinforcement learning. arXiv preprint arXiv:2503.09516. similarity search with GPUs. IEEE Transactions on Big Data, 7(3): 535–547. Joshi, M.; Choi, E.; Weld, D. S.; and Zettlemoyer, L. 2017. TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, 1601–1611. Karpukhin, V.; Oguz, B.; Min, S.; Lewis, P.; Wu, L.; Edunov, S.; Chen, D.; and Yih, W.-t. 2020. Dense Passage Re- trieval for Open-Domain Question Answering. In Web- ber, B.; Cohn, T.; He, Y.; and Liu, Y., eds., Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, 6769–6781. Association for Compu- tational Linguistics. Kwiatkowski, T.; Palomaki, J.; Redfield, O.; Collins, M.; Parikh, A.; Alberti, C.; Epstein, D.; Polosukhin, I.; Devlin, J.; Lee, K.; et al. 2019. Natural questions: a benchmark for question answering research. Transactions of the Associa- tion for Computational Linguistics, 7: 453–466. Lewis, P.; Perez, E.; Piktus, A.; Petroni, F.; Karpukhin, V.; Goyal, N.; K¨uttler, H.; Lewis, M.; Yih, W.-t.; Rockt¨aschel, T.; Riedel, S.; and Kiela, D. 2020. Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. In Larochelle, H.; Ranzato, M.; Hadsell, R.; Balcan, M.; and Lin, H., eds., Advances in Neural Information Processing Systems, volume 33, 9459–9474. Curran Associates, Inc. Li, X.; Dong, G.; Jin, J.; Zhang, Y.; Zhou, Y.; Zhu, Y.; Zhang, P.; and Dou, Z. 2025a. Search-o1: Agentic search-enhanced large reasoning models. arXiv preprint arXiv:2501.05366. Li, Y.; Luo, Q.; Li, X.; Li, B.; Cheng, Q.; Wang, B.; Zheng, Y.; Wang, Y.; Yin, Z.; and Qiu, X. 2025b. R3-RAG: Learn- ing Step-by-Step Reasoning and Retrieval for LLMs via Re- inforcement Learning. arXiv preprint arXiv:2505.23794. Li, Y.; Zhang, W.; Yang, Y.; Huang, W.-C.; Wu, Y.;\n"
     ]
    }
   ],
   "source": [
    "query = \"What are techniques to improve LLM reasoning?\"\n",
    "print_query_result(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889f5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: with a base model and perform forward analysis by computing a breadth-first search (BFS) following the outgoing edges to get that from our LLM supply chain graph. This leads to a forward subgraph, which denotes all the models that depend on the base model, including fine-tuned, adapted, quantized, or merged models. Table 3 shows the top-10 base models sorted by the forward sub- graph size, which is the number of impacted task-specific models. We make two interesting observations. (i) A base model can sig- nificantly impact the LLM supply chain ecosystem. For example, Llama-3.1-8B is a base model from Meta used for efficient text gen- eration, code assistance, and research [19]. Due to its relatively small 5 Table 3: Top-10 base models sorted by forward subgraph size. Base model Total Fine- tune Adapter Quanti- zation Merge Level Llama-3.1-8B 7544 1710 1542 3473 1693 25 Mistral-7B-v0.1 6744 2105 2187 1435 1254 27 Qwen2.5-7B 6733 1972 1764 2516 1132 11 Meta-Llama-3-8B 5633 967 1511 2220 1967 21 Llama-3.1-70B 4063 698 281 2075 2519 11 Qwen2.5-32B 3909 1086 158 2311 1049 12 Qwen2.5-1.5B 3645 1300 1290 949 248 8 Qwen2.5-0.5B 3521 1669 1006 810 46 11 Qwen2.5-14B 3362 726 411 1880 1166 15 Meta-Llama-3-8B-Instruct 3118 640 405 1394 1305 34 size, which allows for deployment in resource-constrained environ- ments, making advanced AI accessible to broader stakeholders [15]. It has generated up to 7,544 models, including 1,710 fine-tuned ver- sions, 1,542 adapters, 3,473 quantizations, and 1,693 merged models tailored to specific tasks. (ii) In terms of fine-tuning, the base model Mistral-7B-v0.1 has been fine-tuned the most times, totaling 2,105. It is a faster and lighter version of the Mistral model from Mistral AI. It is obtained by training on a large corpus with grouped-query and sliding window attention by Mistral AI, delivering efficient text generation, NLP, and code assistance on consumer hardware for low-latency applications like chatbots and text classification [46]. Task-specific model analysis. Given a task-specific model, we want to understand how it evolves, meaning what other models it has relied on. To achieve that, for each task-specific model, we perform a backward analysis by running a BFS following the incoming edges. To that end, the derived subgraph shows the models it relies on. Table 4 shows the top 10 task-specific models sorted by the backward subgraph size, which is the number of models they rely on. We make two interesting observations. (i) A fine-tuned model, command-r-1- layer, illustrates the depth and complexity of transformations in the LLM supply chain. This model operates in bfloat16 (BF16) precision for efficient text generation and natural language understanding [37], originates from the base model cc4ai, and has undergone extensive lineage evolution before reaching its final form. Specifically, it de- pends on 40 upstream artifacts, including 39 other fine-tuned models, and spans 39 transformation levels in its backward lineage chain, as detailed in Table 4. (ii) We observed that adapters are mainly used for lightweight fine-tuning and merges for model integration, but task-specific models like command-r-1-layer, as optimized stan- dalone derivatives, do not evolve from adapters or merges in\n",
      "1: been used to entirely train new models (DeepSeek-AI et al., 2025) or improve model prompting (Pternea et al., 2024), showing great potential for the future. Despite these advances, LLMs remain prone to hallucinations—generating fluent but factu- ally incorrect or logically inconsistent outputs (Huang et al., 2025), (Srivastava et al., 2023), (Ji et al., 2023b). This is especially problematic in knowledge-intensive tasks requiring factual ground- ing, multi-hop reasoning, or domain-specific exper- tise (Ji et al. (2023a), Opsahl (2024)). These issues stem in part from the implicit nature of knowledge storage in model parameters, which limits their abil- ity to verify facts or reason explicitly over external knowledge (Petroni et al. (2019), Bommasani et al. (2021)). Recent work has explored augmenting LLMs with tool use, such as code interpreters (Pi et al., 2022), equation solvers (He-Yueya et al., 2023) or symbolic solvers (Lam et al., 2024) (Pan et al., 2023), to externalize and validate parts of the reasoning process. 2.2 LLMs and graphs Graphs offer a natural and interpretable way to represent real-world data through entities and their structured relationships. Integrating knowledge graphs with Large Language Models (LLMs) is a promising research direction that enables models to better handle real-life scenarios with structured data (Li et al., 2024) (Hu et al., 2024a). Knowledge graphs can enhance LLMs by providing explicit grounded context which 2) LLM LLM LLaMa-2-7B LLaMa-2-7B with and 1) ❄️ ❄️ 🔥 LLM Prompt + GNN Answer LLaMa-2-13B 3) ❄️ Deepseek-R1-Distill- Qwen-32B ❄️ LLM Figure 2: Usage of our decompositional retrieval method: 1) The complex question is first decomposed into atomic subquestions ; 2) We conditionally perform retrieval and answer generation; once the retrieval is done for all subquestions, we merge the subgraphs ; 3) The resulting graph is given as a hard (textualized graph) and soft prompt (graph encoder output) to the model. helps mitigate hallucinations (Li et al., 2024) (Agrawal et al., 2024), but also makes the model dependent on the noise or incompleteness of the graph (Dong et al., 2025). By grounding the generation process in a textualized or symbolic knowledge graph, LLMs can produce responses that are more accurate and aligned with real-world facts. This is especially useful in tasks such as question answering (Baek et al., 2023) (Yasunaga et al., 2021), logical reasoning (Choudhary and Reddy, 2024), or dialogue systems (Kang et al., 2023) where factual precision is crucial. LLMs and graph neural networks (GNNs) can also be used together (Xu et al., 2024) (He et al., 2024a), each complementing the other. Graphs can be used to inject knowledge into LLMs via methods like structured prompting (Baek et al., 2023) (Zhang et al., 2024a) or retrieval-based aug- mentation (Lewis et al., 2020) (Peng et al., 2024). LLMs can support and enhance graph-centred tasks (Pan et al., 2024) by performing entity linking, re- lation extraction, or even link prediction (Shu et al., 2025), which largely improves the graph’s cover- age. LLMs have also been explored as genera- tors of graph-structured outputs or as interpretable reasoning agents over graphs using intermediate symbolic steps. In such hybrid frameworks, LLMs benefit\n",
      "2: is not a static recipe to be discovered, but a dynamic strategy to be learned, paving a principled path toward more autonomous model alignment. AMFT consistently achieved state-of-the-art performance on diverse reasoning benchmarks, with its learned curriculum preventing catastrophic forgetting and policy collapse to yield superior robustness and sample efficiency. Limitations and Future Work. The primary limitation of AMFT is the computational overhead of the meta-gradient, a trade-off for its principled optimization. Its performance also depends on a high-quality validation set and introduces new controller hyperparameters. Future work will therefore focus on developing more efficient meta-gradient approximations and investigating AMFT’s application to other critical alignment challenges. References [1] AI@Meta. Llama 3 model card. 2024. [2] Yuntao Bai, Andy Jones, Kamaldeep Bhasin, Amanda Askell, Anna Chen, Sam Bowman, Avital Vardis, Tom Brown, Ben Mann, Nelson N. DasSarma, Dawn Drain, Stanislav Fort, Zac Hatfield- Dodds, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, T. Hume, Scott Johnston, Tomotake L. J. Kaplan, Anna Goldie, Nova DasSarma, Jared Kaplan, Sam McCandlish, L. Olah, Catherine Olsson, Dario Amodei, Nova McGreggor, Danny Hernandez, Dustin Li, Chris Olah, and Eli Tran-Johnson. Training a helpful and harmless assistant with reinforcement learning from human feedback, 2022. [3] Jack Chen, Fazhong Liu, Naruto Liu, Yuhan Luo, Erqu Qin, Harry Zheng, Tian Dong, Haojin Zhu, Yan Meng, and Xiao Wang. Step-wise adaptive integration of supervised fine-tuning and reinforcement learning for task-specific llms, 2025. [4] Tianzhe Chu, Yuexiang Zhai, Jihan Yang, Shengbang Tong, Saining Xie, Dale Schuurmans, Quoc V. Le, Sergey Levine, and Yi Ma. Sft memorizes, rl generalizes: A comparative study of foundation model post-training, 2025. [5] Hyung Won Chung, Le Hou, Shayne Longpre, et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022. [6] Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. Think you have solved question answering? Try ARC, the AI2 reasoning challenge. arXiv preprint arXiv:1803.05457, 2018. [7] Ganqu Cui, Lifan Yuan, Zefan Wang, Hanbin Wang, Wendi Li, Bingxiang He, Yuchen Fan, Tianyu Yu, Qixin Xu, Weize Chen, and et al. Process reinforcement through implicit rewards, 2025. [8] Ganqu Cui, Lifan Yuan, Zefan Wang, Hanbin Wang, Wendi Li, Bingxiang He, Yuchen Fan, Tianyu Yu, Qixin Xu, Weize Chen, et al. Process reinforcement through implicit rewards. arXiv preprint arXiv:2502.01456, 2025. [9] Heshan Fernando, Han Shen, Parikshit Ram, Yi Zhou, Horst Samulowitz, Nathalie Baracaldo, and Tianyi Chen. Mitigating forgetting in llm supervised fine-tuning and preference learning, 2025. [10] Luca Franceschi, Paolo Frasconi, Saverio Salzo, et al. Bilevel programming for hyperparameter optimization and meta-learning. ICML, 2018. [11] Yuqian Fu, Tinghong Chen, Jiajun Chai, Xihuai Wang, Songjun Tu, Guojun Yin, Wei Lin, Qichao Zhang, Yuanheng Zhu, and Dongbin Zhao. Srft: A single-stage method with supervised and reinforcement fine-tuning for reasoning, 2025. [12] Divyansh Garg, Shuvam Chakraborty, Chris Cundy, Jiaming Song, Matthieu Geist, and Stefano Ermon. Iq-learn: Inverse soft-q learning for imitation, 2022. [13] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948, 2025. [14] Daya Guo, Dejian Yang, Haowei\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "query = \"How do we improve LLM model alignment?\"\n",
    "print_query_result(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
